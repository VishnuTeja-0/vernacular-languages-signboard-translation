{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextTransliteration_MP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMfhg-Gl1Acm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF6Yg5MD1VT5"
      },
      "source": [
        "# Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY0MBOXp1JmY",
        "outputId": "d9a8fb09-d310-4c79-cc76-525c5412f71c"
      },
      "source": [
        "# English Alphabet Set\n",
        "# To enable us to write one hot encoded vectors for individual letters, and thus a vector-of-vectors representations of words, we give each letter in the alphabet a corresponding number\n",
        "# Since transliteration is not case sensitive, we'll not include small letters in our letter-space\n",
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "# Since we want our input to be of uniform size, we need to define a 'pad' character to fill out smaller words\n",
        "pad_char = '-PAD-'               \n",
        "\n",
        "# Assigns each character a numerical value\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvd3N0YV1XDF",
        "outputId": "efb54b3a-709e-4d4a-cdee-ae98f0b6792f"
      },
      "source": [
        "# Hindi Alphabet Set\n",
        "# Hindi Unicode Hex Range is 2304:2432. (Source: https://sites.psu.edu/symbolcodes/languages/southasia/devanagari/devanagarichart/)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnDIYwo11dKg"
      },
      "source": [
        "# Helper Functions for Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxpQmJD81ZG6"
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')    # Regex which returns all characters which are not small or capital letters, or spaces\n",
        "\n",
        "# Function to remove all English non-letters from a line\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()    # Replaces hyphens and commas with spaces from line, so as to get spaces as the uniform delimiter\n",
        "    line = non_eng_letters_regex.sub('', line)                 # Applies above regex on line, replacing every non-letter character with nothing\n",
        "    return line.split()                                        # Splits the line by delimiter (space) into a list and returns it\n",
        "\n",
        "# Function to remove all Hindi non-letters from a line\n",
        "# Since we do not have defined regex for Hindi, we'll have to do the above process manually\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')            # Replaces hyphens and commas with spaces from line, so as to get spaces as the uniform delimiter\n",
        "    # Builds a string by dropping any character which is not in the Devanagari script unicode range, and is not a space\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()                                # Splits the line by delimiter (space) into a list and returns it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "helO43BLOZkE"
      },
      "source": [
        "## Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZZq7PUj1iiO"
      },
      "source": [
        "from torch.utils.data import Dataset           # We import and extend the dataset class from torch, so we can use its functions while building our own dataset\n",
        "import xml.etree.ElementTree as ET             # Library to work with XML files\n",
        "\n",
        "# Class to define and instantiate a dataset\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)    # Initializes the English and Hindi word sets from file using 'readXmlDataset()' function\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))                              # Shuffles the indexes around for variance during training\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "\n",
        "    # Function to return length of word    \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    # Function to return word from language words-list, given index\n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    # Function to parse XML file to extract English and Hindi text words\n",
        "    # An XML document data is hierarchical on purpose to enable easy parsing\n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()    # Parses every root node (every point)\n",
        "        lang1_words = []                                        # List of English words\n",
        "        lang2_words = []                                        # List of Hindi words\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)         # The first tag of a node contains English text\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)        # The second tag of a node contains Hindi text\n",
        "\n",
        "            # Skip noisy data\n",
        "            # Any data where the length of the Englsh and Hindi strings doesn't match are outliers (with letters / sounds fused together) and are thus not considered\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)  \n",
        "                continue\n",
        "\n",
        "            # Pass the words of each language through respective pre-processing functions, and append the vector representation to the lists \n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        " \n",
        "        return lang1_words, lang2_words                         # Returns list for both languages\n",
        "    \n",
        "    # Gets a sample random word from words-list by using the '__getitem__()' function\n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    # Starts from a random index and loops over the whole array to gather 'batch_size' number of datapoints\n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        # If the batch size from the chosen index exceeds the length of the array, we load the rest of the back by looping back to the start of the array\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    # Loads a data batch\n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)       # Gets a random batch of some size for English words\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)   # Gets a random batch of some size for Hindi words\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PFdTYnPOkIe"
      },
      "source": [
        "# Applying above dataloader class onto uploaded XML files\n",
        "# Training set has 13937 datapoints while Test set has 1000 datapoints\n",
        "train_data = TransliterationDataLoader('/content/NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('/content/NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6BRmYl0OlZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212e7898-0968-48a5-d519-2b8dd3f1615d"
      },
      "source": [
        "# Basic Data Visualization\n",
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20641\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "TOIYABE - तोईयाबे\n",
            "TOHDA - टोहड़ा\n",
            "BELAGAAM - बेलगाम\n",
            "HAMMAM - हमाम\n",
            "IRFAN - इरफान\n",
            "GEORGE - जॉर्ज\n",
            "HOGA - होगा\n",
            "AWRA - अव्रा\n",
            "CHIRAAG - चिराग\n",
            "VAASANTEE - वासंती\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vbf9pfTO_0x"
      },
      "source": [
        "## Encoding The Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmYs0UwQPAgR"
      },
      "source": [
        "# This is for the input word, which is in Hindi\n",
        "# Each word will be represented as a vector of one-hot encoded vectors\n",
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "# This is for the output word, which is in English\n",
        "# We shall treat this as a classification task, that is, each letter (one-hot encoded vector) from Hindi input is classified as one of 26 characters in the English alphabet\n",
        "# Thus, the output representation is a vector of class labels\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9yFvHCtPE9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14466e5-8d7f-4bd9-a00f-99b8c4dc1854"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "hindi_rep = word_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_rep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "इंद्रायणी tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0.,  ..., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEp8DRY1PIHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ec8e27-04aa-4947-fdae-38b511d3668c"
      },
      "source": [
        "english_gt = gt_rep(eng, eng_alpha2index)\n",
        "print(eng, english_gt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INDRAYANI tensor([[ 9],\n",
            "        [14],\n",
            "        [ 4],\n",
            "        [18],\n",
            "        [ 1],\n",
            "        [25],\n",
            "        [ 1],\n",
            "        [14],\n",
            "        [ 9],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWHrklkXPWha"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F1yuk4pPYzt"
      },
      "source": [
        "# Encoder Decoder Model using GRUs with Attention Mechanism\n",
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        # Size is increased, as hidden layer at decoder timestep will be augmented with the context vector\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        # Parameters for attention mechanism\n",
        "\n",
        "        # Weight of encoder state vector from current timestep  (whose probability in the distribution is being computed)\n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)                  \n",
        "        # Weight of decoder state vector from previous timestamp\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)                  \n",
        "        # Weight applied to the non-linearity applied to attention function (non-linearity applied to above two quantities)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        # Linear layer converting decoder output at timestamp to size of hidden vector (since we will concatenate context vector with this quantity)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)            \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        # We resize the encoder output to be used in computing context vector\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)        \n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        # Applying coefficient to encoder output\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        # Generating characters timestep by timestep\n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            # Applying coefficient to decoder state, and resizing for addition with encoder output\n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            # Applying coefficient over the attention function, which in turn is a non-linearity over sum of encoder and decoder states\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            # Applying softmax function over V to get a probability distribution\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            # Printing out the dimensions of the attention parameters\n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            # Applying attention probability distribution as weights to the respective encoder outputs\n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "            # Applying dimension transformation on decoder output from previous timestamp (to be passed as input to current timestamp)\n",
        "            # This allows us to concatenate it with the context vector obtained from the attention mechanism\n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            # Concatenation decoder input and attention output to create the final input it to current timestamp of decoder\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            # Printing dimensions of context vector and new decoder input\n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTtdMXHokTYB"
      },
      "source": [
        "# Function to draw inference for a single word when passed through model\n",
        "def infer(net, word, char_limit, device = 'cpu'):\n",
        "    input = word_rep(word, hindi_alpha2index, device)    # Generates numerical representation of input word\n",
        "    return net(input, char_limit)                      # Passes this representation to model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RziV6EaCPkSq"
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(hindi_alpha2index), 256, len(eng_alpha2index), verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeQUsoUxPluQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25301b8-25ca-4f96-c3ab-e31e031ae698"
      },
      "source": [
        "# Dimensional inference\n",
        "out = infer(net_attn, 'उसके', 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([5, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 27])\n",
            "U * Encoder output torch.Size([5, 256])\n",
            "W * Decoder state torch.Size([5, 256])\n",
            "V torch.Size([5, 1])\n",
            "Attn torch.Size([1, 5])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 27])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxuJdLL0Pofz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86f63dc-145a-44b8-c33b-ab06789bd21b"
      },
      "source": [
        "# Running inference on above example (input 'INDIA') on untrained model\n",
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 27]) ग\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n",
            "torch.Size([1, 27]) अ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko86c5rTPud_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSquppNLPxT7"
      },
      "source": [
        "## Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6gJbHR3PvPY"
      },
      "source": [
        "# Function to execute training of model\n",
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    # Pushing network to device\n",
        "    net.train().to(device)\n",
        "    # Setting all gradients to zero\n",
        "    opt.zero_grad()\n",
        "    # Getting a randomly generated batch of training input and output\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    # Iterating through batch\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        # Numerical representation of English input\n",
        "        input = word_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        # Numerical representation of the Hindi output\n",
        "        gt = gt_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        # Calling model, with ground truth passed as additional parameter if teacher forcing (will be directly used during training)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        # Iterating through parameters output by model\n",
        "        for index, output in enumerate(outputs):\n",
        "            # Applying loss function\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            # Computing gradients, 'retain_graph' parameter defines whether or not further training will be done to the model, which can be plotted accordingly on same graph\n",
        "            loss.backward(retain_graph = True)\n",
        "            # Aggregating loss\n",
        "            total_loss += loss\n",
        "\n",
        "    # Applying gradients at the end of batch\n",
        "    opt.step()\n",
        "    # Returns average loss across batch\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ldaDA0P6rB"
      },
      "source": [
        "## Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k-IMiIOP0pA"
      },
      "source": [
        "# Function that sets up the hyperparameters for the training and calls the core training function with these hyperparameters\n",
        "# It also plots the loss per iteration as a graph\n",
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    # Creating network object and moving it to device\n",
        "    net = net.to(device)\n",
        "    # Defining loss function (cross-entropy loss here)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    # Defining optimization function (Adam, here)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    # Defining the number of batches for which teacher forcing will be carried out (here, it is for 1/3rd of the total batches)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    # Iterating over batches\n",
        "    for i in range(n_batches):\n",
        "        # Training function is called with defined hyperparameters, with teacher force value being conditional on batch number\n",
        "        # Average loss after training on batch i is stored  \n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        # Plots Iteration v Loss graph\n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "    \n",
        "    # Checkpoints training for these parameters\n",
        "    torch.save(net, 'model.pt')\n",
        "    # Returns the stored losses of every batch as a list\n",
        "    return loss_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkdoadkjQEMV"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0HK6ap-P9Pp"
      },
      "source": [
        "net = Transliteration_EncoderDecoder_Attention(len(hindi_alpha2index), 256, len(eng_alpha2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDh9ubdbQLdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "77b44865-e014-4c95-a97e-db0bf54dc5fd"
      },
      "source": [
        "loss_history = train_setup(net, lr=0.025, n_batches=500, batch_size = 64, display_freq=100, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 499 Loss 0.1799733191728592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36o5zRjIQV7j"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYHj-tKTQUa9"
      },
      "source": [
        "# Function which draws inference for a given word using a given model\n",
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    eng_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        eng_char = eng_alphabets[index+1]\n",
        "        eng_output += eng_char\n",
        "    print(word + ' - ' + eng_output)\n",
        "    return eng_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FTSwY3TQYhr"
      },
      "source": [
        "# Function which gives accuracy of model given inference of the above 'test' function (which it calls) on the test data\n",
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(eng, eng_alpha2index, device)\n",
        "        outputs = infer(net, hindi, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            eng_pos = indices.tolist()[0]\n",
        "            if eng_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKxX0BdlQaiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49441cf-cc7a-4073-f086-8778021d2133"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "print('Accuracy : ', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  51.02960146063088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTm--N1fPefe"
      },
      "source": [
        "out = infer(net, 'उसके', 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQzYKkv-Wm-4",
        "outputId": "af096abc-156a-4428-b2be-aae2d435416d"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(eng_alpha2index.keys())[list(eng_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 27]) O\n",
            "torch.Size([1, 27]) S\n",
            "torch.Size([1, 27]) K\n",
            "torch.Size([1, 27]) E\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n",
            "torch.Size([1, 27]) -PAD-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-qhPGSOMyr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339461ff-4b5f-4af9-cf23-f9a346d34df6"
      },
      "source": [
        "print('keep_me_alive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keep_me_alive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK_N8SK3Q83t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}